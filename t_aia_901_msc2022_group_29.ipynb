{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "t-aia-901-msc2022-group-29.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# T9 - Artificial intelligence (T-DAT-901)\n",
        "## Travel Order Resolver\n",
        "Project members:\n",
        "* Matisse AUBRY\n",
        "* Georges BITAKWIRE\n",
        "* Loan JOUFFROY\n",
        "* Raphaël LÉVY \n",
        "* Marco VIALLEFONT"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "id": "ghsZnZJ74qpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project setup"
      ],
      "metadata": {
        "id": "S7V85pB54qpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "!python -m spacy download fr_core_news_sm\n",
        "!pip install geograpy3==0.1.2\n",
        "from langdetect import detect\n",
        "import fr_core_news_sm\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import geograpy\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "\n",
        "\n",
        "nlp = fr_core_news_sm.load()\n",
        "print(\"Project setup\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T11:56:51.285633Z",
          "iopub.execute_input": "2022-01-07T11:56:51.285884Z",
          "iopub.status.idle": "2022-01-07T11:57:56.625078Z",
          "shell.execute_reply.started": "2022-01-07T11:56:51.285854Z",
          "shell.execute_reply": "2022-01-07T11:57:56.624060Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW_uHrHH4qpV",
        "outputId": "4f72776f-15e9-4cb3-8a5c-8e754cbe109a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "Requirement already satisfied: geograpy3==0.1.2 in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from geograpy3==0.1.2) (3.2.5)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.7/dist-packages (from geograpy3==0.1.2) (20.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geograpy3==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.7/dist-packages (from geograpy3==0.1.2) (0.8.9)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.7/dist-packages (from geograpy3==0.1.2) (0.2.8)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (3.13)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (2.23.0)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (2.8.2)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (0.0.4)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (7.1.2)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (0.35.1)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (3.1.2)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (4.6.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (6.0.8)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k->geograpy3==0.1.2) (1.15.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser>=5.2.1->newspaper3k->geograpy3==0.1.2) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==0.1.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==0.1.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==0.1.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==0.1.2) (3.0.4)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->geograpy3==0.1.2) (1.5.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->geograpy3==0.1.2) (3.4.0)\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "Project setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LANGUAGES_ACCEPTED = ['fr'] # => If, one day, we wish add new languages\n",
        "\n",
        "# Return True if the input have a accpected language, else return False\n",
        "def check_if_text_accepted_language(text):\n",
        "    accepted = False\n",
        "    lang_detected = detect(text)\n",
        "    for langue in LANGUAGES_ACCEPTED:\n",
        "        if (langue == lang_detected):\n",
        "            accepted = True\n",
        "    return accepted"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:15:10.071687Z",
          "iopub.execute_input": "2022-01-06T15:15:10.0726Z",
          "iopub.status.idle": "2022-01-06T15:15:10.078504Z",
          "shell.execute_reply.started": "2022-01-06T15:15:10.072542Z",
          "shell.execute_reply": "2022-01-06T15:15:10.077908Z"
        },
        "trusted": true,
        "id": "XDCEzd0H4qpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_arrival():\n",
        "  "
      ],
      "metadata": {
        "id": "0tvwPszL8jZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_departure(sentence):\n",
        "  doc = nlp(sentence)\n",
        "  print([token.lemma_ for token in doc])\n",
        "  phrase_sent = [(X, X.pos_) for X in doc]\n",
        "  places = geograpy.get_place_context(text=sentence)\n",
        "#     nlp_wk = spacy.load('xx_ent_wiki_sm')\n",
        "    \n",
        "  adp =  [word for word,pos in phrase_sent if pos == 'ADP']\n",
        "  prop = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "  city = [(X.text) for X in doc.ents]\n",
        "  print(adp)\n",
        "  if(len(adp)>1):\n",
        "    adp = str(adp)\n",
        "    print(city)\n",
        "    adp = adp.replace(\"pour,\", \"\")\n",
        "    adp = adp.replace(\"en,\", \"\")\n",
        "    adp = adp.replace(\"en\", \"\")\n",
        "    adp = adp.replace(\"dans,\", \"\")\n",
        "    adp = adp.replace(\" \", \"\")\n",
        "    \n",
        "    print(adp)\n",
        "    adp = nlp(adp)\n",
        "    \n",
        "    adp_word =  [(X, X.pos_) for X in adp]\n",
        "    print(adp_word)\n",
        "    real_adp = [word for word,pos in adp_word if pos == 'ADP'] \n",
        "    adp = real_adp\n",
        "    print(len(str(adp)))\n",
        "  dictionary = {\"departure\":[\"de\",\"depuis\",\"à\", \"par\",\"vers\"]}\n",
        "  print(prop)\n",
        "  for cle, valeur in dictionary.items():\n",
        "    if not adp or valeur[0] == str(adp[0]):\n",
        "      if(str(city[0]) == \"\"):\n",
        "        print(prop[0])\n",
        "      else:\n",
        "        print(city[0])\n",
        "    elif valeur[4] == str(adp[0]):\n",
        "      if(str(city[0]) == \"\"):\n",
        "        print(prop[0])\n",
        "      else:\n",
        "        print(city[0])\n",
        "    elif valeur[2] == str(adp[0]) and  len(str(adp)) > 1 and valeur[2] == str(adp[1]):\n",
        "      if(str(city[1]) == \"\"):\n",
        "        print(prop[1])\n",
        "      else:\n",
        "        print(city[1])\n",
        "    elif valeur[2] == str(adp[0]):\n",
        "      if(str(city[1]) == \"\"):\n",
        "        print(prop[1])\n",
        "      else:\n",
        "        print(city[1])\n",
        "    elif valeur[1] == str(adp[0]) or str(adp[1]):\n",
        "      if(str(city[1]) == \"\"):\n",
        "        print(prop[1])\n",
        "      else:\n",
        "        print(city[1])\n",
        "    elif valeur[3] == str(adp[1]):\n",
        "      if(str(city[1]) == \"\"):\n",
        "        print(prop[1])\n",
        "      else:\n",
        "        print(city[1])\n",
        "    else:\n",
        "      if(str(city[0]) == \"\"):\n",
        "        print(prop[0])\n",
        "      else:\n",
        "        print(city[0])\n",
        "return_departure(\"Je suis actuellement à Nice et je veux me rendre à Marseille\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkS8Hpqh8dZp",
        "outputId": "f581ac0e-2fe7-40ba-c4ea-8bd2fdc7a27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['je', 'être', 'actuellement', 'à', 'nice', 'et', 'je', 'veux', 'me', 'rendre', 'à', 'Marseille']\n",
            "[à, à]\n",
            "['Nice', 'Marseille']\n",
            "[à,à]\n",
            "[([, 'PUNCT'), (à, 'ADP'), (,, 'PUNCT'), (à, 'ADP'), (], 'PUNCT')]\n",
            "6\n",
            "[Marseille]\n",
            "Marseille\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_POS(sentence):\n",
        "#     for i in\n",
        "#range(0, len(adp)):\n",
        "#         if adp[i] == \"de:\n",
        "#             proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#             print(\"departure {}\".format(proper_noun[0]))\n",
        "#         if adp[i] == \"depuis\":\n",
        "#             proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#             print(\"departure {}\".format(proper_noun[1]))\n",
        "#         elif adp[i] == \"à\":\n",
        "#             proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#             print(\"departure {}\".format(proper_noun[1]))\n",
        "#         if adp[i] == \"à\":\n",
        "#             proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#             print(\"arrival {}\".format(proper_noun[0]))\n",
        "#         if adp[i] == \"à\":\n",
        "#             proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#             print(\"arrival {}\".format(proper_noun[1]))\n",
        "#         if adp[i] == \"vers\":\n",
        "#             proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#             print(\"arrival {}\".format(proper_noun[1]))\n",
        "    lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
        "    doc = nlp(sentence)\n",
        "    print([token.lemma_ for token in doc])\n",
        "    phrase_sent = [(X, X.pos_) for X in doc]\n",
        "    places = geograpy.get_place_context(text=sentence)\n",
        "#     nlp_wk = spacy.load('xx_ent_wiki_sm')\n",
        "    \n",
        "    adp =  [word for word,pos in phrase_sent if pos == 'ADP']\n",
        "    prop = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "    city = [(X.text) for X in doc.ents]\n",
        "#     print(phrase_sent)\n",
        "#     print(str(adp))\n",
        "#     print(prop)\n",
        "#     print(city)\n",
        "#     print(places.cities)\n",
        "    \n",
        "    \n",
        "    adp = str(adp)\n",
        "    disallowed_characters = [\"par\",\"pour\",\"en\",\"vers\"]\n",
        "    adp_forbiden = str(disallowed_characters)\n",
        "    print(adp_forbiden)            \n",
        "    dictionary = {\"arrival\": [\"à\", \"vers\"],\"departure\":[\"de\",\"depuis\",\"à\"]}\n",
        "    \n",
        "    for cle, valeur in dictionary.items():\n",
        "        for i in adp:\n",
        "            if not adp:\n",
        "                        arrival = prop[1]\n",
        "                        departure = prop[0]\n",
        "                        print(\"departure {}\".format(departure))\n",
        "                        print(\"arrival {}\".format(arrival))\n",
        "            if str(i) == \"à\" or str(i) == \"de\":\n",
        "                        adp = adp.replace(\"par\", \"\")\n",
        "                        adp = adp.replace(\"pour\", \"\")\n",
        "                        adp = adp.replace(\"en\", \"\")\n",
        "                        print(adp)\n",
        "        if cle == \"arrival\" and valeur[0] == str(adp[0]):\n",
        "                arrival = city[0]\n",
        "                departure = city[1]\n",
        "                print(\"departure {}\".format(departure))\n",
        "                print(\"arrival {}\".format(arrival))\n",
        "        elif cle == \"departure\" and valeur[0] == str(adp[0]):\n",
        "                arrival = city[1]\n",
        "                departure = city[0]\n",
        "                print(\"departure {}\".format(departure))\n",
        "                print(\"arrival {}\".format(arrival))\n",
        "        elif cle == \"departure\" and valeur[1] == str(adp[0]):\n",
        "                arrival = city[0]\n",
        "                departure = city[1]\n",
        "                print(\"departure {}\".format(departure))\n",
        "                print(\"arrival {}\".format(arrival))            \n",
        "            \n",
        "#     if len(adp) == 0 or len(adp) >= 2:\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"arrival {}\".format(proper_noun[1]))\n",
        "#         print(\"departure {}\".format(proper_noun[0]))\n",
        "#     if str(adp[0]) == \"de\" and str(adp[1]) != \"depuis\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[0]))\n",
        "#     if str(adp[1]) == \"de\" :\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[0]))\n",
        "#     if str(adp[0]) == \"de\" and str(adp[1]) == \"depuis\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"arrival {}\".format(proper_noun[0]))    \n",
        "#     if str(adp[0]) == \"depuis\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[0]))\n",
        "#     if str(adp[1]) == \"depuis\":\n",
        "#         proper_noun = [wor<d for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[1]))\n",
        "#     if str(adp[0]) == \"à\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"arrival {}\".format(proper_noun[0]))\n",
        "#     if str(adp[0]) == \"à\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[1]))\n",
        "#     if str(adp[1]) == \"vers\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"arrival {}\".format(proper_noun[1]))\n",
        "#     if len(adp) == 2 and str(adp[1]) == \"à\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"arrival {}\".format(proper_noun[1]))#à revoir\n",
        "#     if len(adp) == 2 and str(adp[1]) == \"à\" and len(proper_noun) == 2:\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[2]))\n",
        "#     if len(adp) >= 3 and str(adp[3]) == \"par\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[1]))\n",
        "#     if len(adp) >= 3 and str(adp[2]) == \"par\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[1]))\n",
        "#     if len(adp) >= 3 and str(adp[2]) == \"par\" and str(adp[1]) == \"à\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"departure {}\".format(proper_noun[1]))  \n",
        "#     if len(adp) >= 3 and str(adp[2]) == \"à\"and str(adp[1]) != \"pour\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"arrival {}\".format(proper_noun[1]))\n",
        "#     if len(adp) >= 3 and str(adp[1]) == \"à\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"arrival {}\".format(proper_noun[0]))\n",
        "#     if len(adp) >= 3 and str(adp[2]) == \"depuis\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"depature {}\".format(proper_noun[1]))\n",
        "#     if len(adp) >= 3 and str(adp[2]) == \"à\" and str(adp[1]) ==\"pour\":\n",
        "#         proper_noun = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "#         print(\"arrival {}\".format(proper_noun[1]))\n",
        "return_POS(\"de Marseille à Paris\")"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-01-07T14:00:02.589434Z",
          "iopub.execute_input": "2022-01-07T14:00:02.589746Z",
          "iopub.status.idle": "2022-01-07T14:00:02.700159Z",
          "shell.execute_reply.started": "2022-01-07T14:00:02.589712Z",
          "shell.execute_reply": "2022-01-07T14:00:02.698988Z"
        },
        "trusted": true,
        "id": "86yu1_5g4qpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0kJbX_RF4qpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect all locations in a sentence\n",
        "def detect_destinations(sentence):\n",
        "    # Tokeniser la phrase\n",
        "    doc = nlp(sentence)\n",
        "    words = [X.text for X in doc]\n",
        "\n",
        "    # Keep only usefull words\n",
        "    clean_words = []\n",
        "    for token in words:\n",
        "        if token not in stopWords:\n",
        "            clean_words.append(token)\n",
        "    clean_words = ' '.join(clean_words)\n",
        "    \n",
        "    # Get only destinations\n",
        "    doc_cleaned = nlp(sentence) # Remettre clean_words\n",
        "    ##print(doc_cleaned)\n",
        "    for token in doc:\n",
        "        print(token.text, token.dep_, token.head.text, token.head.pos_,[child for child in token.children])\n",
        "    destinations = []\n",
        "    for X in doc.ents: \n",
        "        if (X.label_ == 'LOC'):\n",
        "            print(destinations.append(X.text))\n",
        "    return destinations"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T12:36:34.811412Z",
          "iopub.execute_input": "2021-12-16T12:36:34.812224Z",
          "iopub.status.idle": "2021-12-16T12:36:34.819843Z",
          "shell.execute_reply.started": "2021-12-16T12:36:34.812181Z",
          "shell.execute_reply": "2021-12-16T12:36:34.818825Z"
        },
        "trusted": true,
        "id": "w62bX7ZZ4qpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_function(input):\n",
        "    # => Transform input to text\n",
        "    text = input\n",
        "    if (check_if_text_accepted_language(text)):\n",
        "        detect_destinations(text)\n",
        "    else:\n",
        "        print(\"/!\\ Please, speak french\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T12:34:07.708287Z",
          "iopub.execute_input": "2021-12-16T12:34:07.708818Z",
          "iopub.status.idle": "2021-12-16T12:34:07.714672Z",
          "shell.execute_reply.started": "2021-12-16T12:34:07.708742Z",
          "shell.execute_reply": "2021-12-16T12:34:07.71369Z"
        },
        "trusted": true,
        "id": "1jjwqi1L4qpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_function(\"Je veux aller de Marseille vers Paris\")\n",
        "# Marseille obl:arg aller VERB [de]\n",
        "# Paris obl:mod aller VERB [vers]\n",
        "\n",
        "\n",
        "print(\"-------------\")\n",
        " \n",
        "\n",
        "main_function(\"Je veux arriver à Paris depuis la ville de Marseille en train\")\n",
        "# Paris obl:arg arriver VERB [à]\n",
        "# Marseille nmod ville NOUN [de]\n",
        "\n",
        "#main_function(\"Hi, I want to go to Paris from Marseille\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T12:34:10.306653Z",
          "iopub.execute_input": "2021-12-16T12:34:10.307532Z",
          "iopub.status.idle": "2021-12-16T12:34:11.371558Z",
          "shell.execute_reply.started": "2021-12-16T12:34:10.307458Z",
          "shell.execute_reply": "2021-12-16T12:34:11.370491Z"
        },
        "trusted": true,
        "id": "H9sfDY584qpd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}