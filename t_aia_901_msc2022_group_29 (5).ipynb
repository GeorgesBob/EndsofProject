{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "t-aia-901-msc2022-group-29.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# T9 - Artificial intelligence (T-DAT-901)\n",
        "## Travel Order Resolver\n",
        "Project members:\n",
        "* Matisse AUBRY\n",
        "* Georges BITAKWIRE\n",
        "* Loan JOUFFROY\n",
        "* Raphaël LÉVY \n",
        "* Marco VIALLEFONT"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "id": "ghsZnZJ74qpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project setup"
      ],
      "metadata": {
        "id": "S7V85pB54qpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "!python -m spacy download fr_core_news_sm\n",
        "!apt remove libav-tools\n",
        "!pip install geograpy3==0.1.2\n",
        "!pip install pydub\n",
        "!pip install SpeechRecognition\n",
        "import ipywidgets as widgets\n",
        "from IPython import display as disp\n",
        "from IPython.display import display, Audio, clear_output\n",
        "from google.colab import output\n",
        "import base64\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "import tempfile\n",
        "import librosa\n",
        "import numpy as np\n",
        "from langdetect import detect\n",
        "import fr_core_news_sm\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import geograpy\n",
        "import speech_recognition as sr\n",
        "from scipy.io.wavfile import write\n",
        "import soundfile\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "\n",
        "\n",
        "nlp = fr_core_news_sm.load()\n",
        "print(\"Project setup\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-07T11:56:51.285633Z",
          "iopub.execute_input": "2022-01-07T11:56:51.285884Z",
          "iopub.status.idle": "2022-01-07T11:57:56.625078Z",
          "shell.execute_reply.started": "2022-01-07T11:56:51.285854Z",
          "shell.execute_reply": "2022-01-07T11:57:56.624060Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW_uHrHH4qpV",
        "outputId": "2b6a9d93-d678-434b-c41d-c4cc5a4d734f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 122 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 153 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 184 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 194 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 204 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 215 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 225 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 235 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 245 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 256 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 266 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 286 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 296 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 317 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 327 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 348 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 358 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 378 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 389 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 409 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 419 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 440 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 450 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 471 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 481 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 501 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 512 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 532 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 542 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 563 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 573 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 593 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 604 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 624 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 634 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 655 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 665 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 686 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 696 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 716 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 727 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 747 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 757 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 768 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 778 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 788 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 798 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 808 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 819 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 829 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 839 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 849 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 860 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 870 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 880 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 890 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 901 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 911 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 921 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 931 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 942 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 952 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 962 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 972 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 981 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=6fb7f0c2f9b313daf151dcab663e3357d9773a9379c275f7abd700b658a3e5c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-py3-none-any.whl size=14727025 sha256=b294af7b5bcd11e6962f5b2cb584b1487cc4d25cb5b709c65d06af79495648f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-blygpwi9/wheels/c9/a6/ea/0778337c34660027ee67ef3a91fb9d3600b76777a912ea1c24\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package 'libav-tools' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Collecting geograpy3==0.1.2\n",
            "  Downloading geograpy3-0.1.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 9.8 MB/s \n",
            "\u001b[?25hCollecting pycountry\n",
            "  Downloading pycountry-22.1.10.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from geograpy3==0.1.2) (3.2.5)\n",
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 53.2 MB/s \n",
            "\u001b[?25hCollecting jellyfish\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geograpy3==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (7.1.2)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (2.23.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (3.13)\n",
            "Collecting tldextract>=2.0.1\n",
            "  Downloading tldextract-3.1.2-py2.py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (4.2.6)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "Collecting jieba3k>=0.35.1\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (2.8.2)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "Collecting feedparser>=5.2.1\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k->geograpy3==0.1.2) (4.6.3)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k->geograpy3==0.1.2) (1.15.0)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==0.1.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==0.1.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==0.1.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k->geograpy3==0.1.2) (3.0.4)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k->geograpy3==0.1.2) (3.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pycountry->geograpy3==0.1.2) (57.4.0)\n",
            "Building wheels for collected packages: jellyfish, tinysegmenter, feedfinder2, jieba3k, pycountry, sgmllib3k\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73989 sha256=77080e8f6097cf3c1fd2f3cbf832c8945efb8f2e2601e92d45e5b8cacb855d10\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13553 sha256=bf803d0003987008a4aa093845aa3f925ee8836867da9176e9b3e2a70ff41f2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3357 sha256=e2e0743acec0134321356a785432057c12ae7731e4a438e30aba521a068ca9ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=10b5c41ab4b946ee17e1a8ba3c4744acc8107ce1fe613cb5600075d47369acb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.1.10-py2.py3-none-any.whl size=10595784 sha256=3b66cd66868eb9421dd8ebf5fcf63e67a3d1cc2319390bfd09b24a22e4709fca\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/8f/9c/b070d7376caf2beb0685bf72578106b2fd57019ed57d84f126\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=faa432dd9ecc64e1798ff3d227d467aecef7607c90dba2093ae1e516c811798c\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built jellyfish tinysegmenter feedfinder2 jieba3k pycountry sgmllib3k\n",
            "Installing collected packages: sgmllib3k, requests-file, tldextract, tinysegmenter, jieba3k, feedparser, feedfinder2, cssselect, pycountry, newspaper3k, jellyfish, geograpy3\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.8 geograpy3-0.1.2 jellyfish-0.9.0 jieba3k-0.35.1 newspaper3k-0.2.8 pycountry-22.1.10 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.2\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 73.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "Project setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def record_audio(seconds=3,\n",
        "                 sample_rate=44100,\n",
        "                 normalize_db=0.1):\n",
        "    \"\"\"Record audio from the browser in colab using javascript.\n",
        "    Based on: https://gist.github.com/korakot/c21c3476c024ad6d56d5f48b0bca92be\n",
        "    Args:\n",
        "      seconds: Number of seconds to record.\n",
        "      sample_rate: Resample recorded audio to this sample rate.\n",
        "      normalize_db: Normalize the audio to this many decibels. Set to None to skip\n",
        "        normalization step.\n",
        "    Returns:\n",
        "      An array of the recorded audio at sample_rate.\n",
        "    \"\"\"\n",
        "    # Use Javascript to record audio.\n",
        "    record_js_code = \"\"\"\n",
        "      const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "      const b2text = blob => new Promise(resolve => {\n",
        "        const reader = new FileReader()\n",
        "        reader.onloadend = e => resolve(e.srcElement.result)\n",
        "        reader.readAsDataURL(blob)\n",
        "      })\n",
        "      var record = time => new Promise(async resolve => {\n",
        "        stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "        recorder = new MediaRecorder(stream)\n",
        "        chunks = []\n",
        "        recorder.ondataavailable = e => chunks.push(e.data)\n",
        "        recorder.start()\n",
        "        await sleep(time)\n",
        "        recorder.onstop = async ()=>{\n",
        "          blob = new Blob(chunks)\n",
        "          text = await b2text(blob)\n",
        "          resolve(text)\n",
        "        }\n",
        "        recorder.stop()\n",
        "      })\n",
        "      \"\"\"\n",
        "    print('Starting recording for {} seconds...'.format(seconds))\n",
        "    display(disp.Javascript(record_js_code))\n",
        "    audio_string = output.eval_js('record(%d)' % (seconds * 1000.0))\n",
        "    print('Finished recording!')\n",
        "    audio_bytes = base64.b64decode(audio_string.split(',')[1])\n",
        "    return audio_bytes_to_np(audio_bytes,\n",
        "                             sample_rate=sample_rate,\n",
        "                             normalize_db=normalize_db)\n",
        "    \n",
        "def audio_bytes_to_np(wav_data,\n",
        "                      sample_rate=44100,\n",
        "                      normalize_db=0.1):\n",
        "    \"\"\"Convert audio file data (in bytes) into a numpy array.\n",
        "    Saves to a tempfile and loads with librosa.\n",
        "    Args:\n",
        "      wav_data: A byte stream of audio data.\n",
        "      sample_rate: Resample recorded audio to this sample rate.\n",
        "      normalize_db: Normalize the audio to this many decibels. Set to None to skip\n",
        "        normalization step.\n",
        "    Returns:\n",
        "      An array of the recorded audio at sample_rate.\n",
        "    \"\"\"\n",
        "    # Parse and normalize the audio.\n",
        "    audio = AudioSegment.from_file(io.BytesIO(wav_data))\n",
        "    audio.remove_dc_offset()\n",
        "    if normalize_db is not None:\n",
        "        audio.normalize(headroom=normalize_db)\n",
        "    # Save to tempfile and load with librosa.\n",
        "    with tempfile.NamedTemporaryFile(suffix='.wav') as temp_wav_file:\n",
        "        fname = temp_wav_file.name\n",
        "        audio.export(fname, format='wav')\n",
        "        audio_np, unused_sr = librosa.load(fname, sr=sample_rate)\n",
        "    return audio_np"
      ],
      "metadata": {
        "id": "EQurHLwJm0nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Record\n",
        "#@markdown * Set recording time:\n",
        "\n",
        "SAMPLE_RATE = 44100\n",
        "record_seconds =   4 #@param {type:\"number\", min:2, max:10, step:1}\n",
        "NAME_FILE = 'record.wav'\n",
        "\n",
        "def record_new_audio_and_save_it(b=None, view_audio_return=True, record_time=record_seconds):\n",
        "  print(\"Start recording...\")\n",
        "  global audio\n",
        "  clear_output()\n",
        "  audio = record_audio(record_time, sample_rate=SAMPLE_RATE)\n",
        "\n",
        "  if view_audio_return is True:\n",
        "    display(Audio(audio, rate=SAMPLE_RATE))\n",
        "\n",
        "  # Supprime le fichier s'il existe\n",
        "  if os.path.exists(NAME_FILE):\n",
        "    os.remove(NAME_FILE)\n",
        "\n",
        "  write(NAME_FILE,SAMPLE_RATE, audio)\n",
        "  data, samplerate = soundfile.read(NAME_FILE)\n",
        "  soundfile.write(NAME_FILE, data, samplerate, subtype='PCM_16')\n",
        "\n",
        "# # For test the record_new_audio_and_save_it function\n",
        "# button = widgets.Button(description=\"Start recording...\")\n",
        "# button.on_click(record_new_audio_and_save_it)\n",
        "# display(button)"
      ],
      "metadata": {
        "id": "FoHqTVrpc0pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_to_text(source_audio_file='/content/' + NAME_FILE):\n",
        "  r = sr.Recognizer()\n",
        "  with sr.AudioFile(source_audio_file) as source:\n",
        "      # listen for the data (load audio to memory)\n",
        "      audio_data = r.record(source)\n",
        "      # recognize (convert from speech to text)\n",
        "      text = r.recognize_google(audio_data, language=\"fr-FR\")\n",
        "      print('Speech to text out : ' + text)\n",
        "      return text"
      ],
      "metadata": {
        "id": "iNpy8dhApkI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LANGUAGES_ACCEPTED = ['fr'] # => If, one day, we wish add new languages\n",
        "\n",
        "# Return True if the input have a accpected language, else return False\n",
        "def check_if_text_accepted_language(text):  \n",
        "    accepted = False\n",
        "    lang_detected = detect(text)\n",
        "    for langue in LANGUAGES_ACCEPTED:\n",
        "        if (langue == lang_detected):\n",
        "            accepted = True\n",
        "    return accepted"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:15:10.071687Z",
          "iopub.execute_input": "2022-01-06T15:15:10.0726Z",
          "iopub.status.idle": "2022-01-06T15:15:10.078504Z",
          "shell.execute_reply.started": "2022-01-06T15:15:10.072542Z",
          "shell.execute_reply": "2022-01-06T15:15:10.077908Z"
        },
        "trusted": true,
        "id": "XDCEzd0H4qpX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_arrival(sentence):\n",
        "  if(sentence == \"\"):\n",
        "    print(\"veuillez saisir votre phrase\")\n",
        "  else:\n",
        "    doc = nlp(sentence)\n",
        "    verb = [token.lemma_ for token in doc]\n",
        "    phrase_sent = [(X, X.pos_) for X in doc]\n",
        "    places = geograpy.get_place_context(text=sentence)\n",
        "  #     nlp_wk = spacy.load('xx_ent_wiki_sm')\n",
        "      \n",
        "    adp =  [word for word,pos in phrase_sent if pos == 'ADP']\n",
        "    prop = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "    city = [(X.text) for X in doc.ents]\n",
        "    # print(adp)\n",
        "    if(len(adp)>=1):\n",
        "      adp = str(adp)\n",
        "      # print(city)\n",
        "      adp = adp.replace(\"pour,\", \"\")\n",
        "      adp = adp.replace(\"Bonjour\", \"\")\n",
        "      adp = adp.replace(\"Depuis\", \"depuis\")\n",
        "      adp = adp.replace(\"De\", \"de\")\n",
        "      adp = adp.replace(\"entre\", \"de\")\n",
        "      adp = adp.replace(\"depuis\", \"de\")\n",
        "      adp = adp.replace(\"en,\", \"\")\n",
        "      adp = adp.replace(\"en\", \"\")\n",
        "      adp = adp.replace(\"dans,\", \"\")\n",
        "      adp = adp.replace(\" \", \"\")\n",
        "      \n",
        "      # print(adp)\n",
        "      adp = nlp(adp)\n",
        "      \n",
        "      adp_word =  [(X, X.pos_) for X in adp]\n",
        "      # print(adp_word)\n",
        "      real_adp = [word for word,pos in adp_word if pos == 'ADP'] \n",
        "      adp = real_adp\n",
        "      # print(len(str(adp)))\n",
        "    dictionary = {\"arrival\":[\"de\",\"depuis\",\"à\", \"par\",\"vers\"]} \n",
        "    arrival = None\n",
        "    for cle, valeur in dictionary.items():\n",
        "      if not adp or valeur[0] == str(adp[0]):\n",
        "        if len(city) == 1:\n",
        "          city = str(city)\n",
        "          city = nlp(city)\n",
        "          city_word = [(X, X.pos_) for X in city]\n",
        "          real_city = [word for word,pos in city_word if pos == 'PROPN'] \n",
        "          city = real_city\n",
        "        \n",
        "        if(str(city[1]) == \"\"):\n",
        "          arrival = prop[1]\n",
        "          #print(\"arrival : \",prop[1])\n",
        "        else:\n",
        "          arrival = city[1]\n",
        "          print(\"arrival : \",city[1])\n",
        "      elif valeur[4] == str(adp[0]):\n",
        "        if(str(city[1]) == \"\"):\n",
        "          arrival = prop[1]\n",
        "          #print(\"arrival : \",prop[1])\n",
        "        else:\n",
        "          arrival = city[1]\n",
        "          #print(\"arrival : \",city[1])\n",
        "      elif valeur[2] == str(adp[0]) and str(verb[2]) == \"être\":\n",
        "        if(str(city[1]) == \"\"):\n",
        "          arrival = prop[1]\n",
        "          print(\"arrival : \",prop[1])\n",
        "        else:\n",
        "          arrival = city[1]\n",
        "          # print(\"arrival : \",city[1])\n",
        "      elif valeur[2] == str(adp[0]):\n",
        "        if(str(city[0]) == \"\"):\n",
        "          arrival = prop[0]\n",
        "          # print(\"arrival : \",prop[0])\n",
        "        else:\n",
        "          if len(city) == 3:\n",
        "            arrival = city[0] \n",
        "          else:\n",
        "            arrival = city[0]\n",
        "          # print(\"arrival : \",city[0])\n",
        "      elif valeur[2] == str(adp[0]):\n",
        "        if(str(city[0]) == \"\"):\n",
        "          arrival = prop[0]\n",
        "          # print(\"arrival : \",prop[0])\n",
        "        else:\n",
        "          arrival = city[0]\n",
        "          # print(\"arrival : \",city[0])\n",
        "      elif valeur[1] == str(adp[0]) or str(adp[1]):\n",
        "        if(str(city[0]) == \"\"):\n",
        "          arrival = prop[0]\n",
        "          # print(\"arrival : \",prop[0])\n",
        "        else:\n",
        "          arrival = city[0]\n",
        "          # print(\"arrival : \",city[0])\n",
        "      elif valeur[3] == str(adp[1]):\n",
        "        if(str(city[0]) == \"\"):\n",
        "          arrival = prop[0]\n",
        "          # print(\"arrival : \",prop[0])\n",
        "        else:\n",
        "          arrival = city[0]\n",
        "          # print(\"arrival : \",city[0])\n",
        "      else:\n",
        "        if(str(city[1]) == \"\"):\n",
        "          arrival = prop[1]\n",
        "          # print(\"arrival : \",prop[1])\n",
        "        else:\n",
        "          arrival = city[1]\n",
        "          # print(\"arrival : \",city[1])\n",
        "      return arrival\n",
        "return_arrival(\"\")\n"
      ],
      "metadata": {
        "id": "0tvwPszL8jZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "397a48bf-e6ca-4b1b-fd2c-17ab4f1a94f1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Mcdonald'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_departure(sentence):\n",
        "  if(sentence == \"\"):\n",
        "    print(\"veuillez saisir votre phrase\")\n",
        "  else:\n",
        "    doc = nlp(sentence)\n",
        "    verb = [token.lemma_ for token in doc]\n",
        "    phrase_sent = [(X, X.pos_) for X in doc]\n",
        "    places = geograpy.get_place_context(text=sentence)\n",
        "  #     nlp_wk = spacy.load('xx_ent_wiki_sm')\n",
        "    adp =  [word for word,pos in phrase_sent if pos == 'ADP']\n",
        "    prop = [word for word,pos in phrase_sent if pos == 'PROPN']\n",
        "    city = [(X.text) for X in doc.ents]\n",
        "    print(city)\n",
        "    # print(adp)\n",
        "    if(len(adp)>=1):\n",
        "      adp = str(adp)\n",
        "      # print(city)\n",
        "      adp = adp.replace(\"pour,\", \"\")\n",
        "      adp = adp.replace(\"De\", \"de\")\n",
        "      adp = adp.replace(\"Depuis\", \"depuis\")\n",
        "      adp = adp.replace(\"depuis\", \"de\")\n",
        "      adp = adp.replace(\"Bonjour\", \"\")\n",
        "      adp = adp.replace(\"en,\", \"\")\n",
        "      adp = adp.replace(\"entre\", \"de\")\n",
        "      adp = adp.replace(\"en\", \"\")\n",
        "      adp = adp.replace(\"dans,\", \"\")\n",
        "      adp = adp.replace(\" \", \"\")\n",
        "      \n",
        "      # print(adp)\n",
        "      adp = nlp(adp)\n",
        "      \n",
        "      adp_word =  [(X, X.pos_) for X in adp]\n",
        "      # print(adp_word)\n",
        "      real_adp = [word for word,pos in adp_word if pos == 'ADP'] \n",
        "      adp = real_adp\n",
        "      # print(len(str(adp)))\n",
        "    dictionary = {\"departure\":[\"de\",\"depuis\",\"à\", \"par\",\"vers\"]}\n",
        "    # print(prop)\n",
        "    departure = None\n",
        "    for cle, valeur in dictionary.items():\n",
        "      if not adp or valeur[0] == str(adp[0]):\n",
        "        if len(city) == 1:\n",
        "          city = str(city)\n",
        "          city = nlp(city)          \n",
        "          city_word = [(X, X.pos_) for X in city]\n",
        "          real_city = [word for word,pos in city_word if pos == 'PROPN'] \n",
        "          print(real_city)\n",
        "          city = real_city\n",
        "        else: \n",
        "          if(str(city[0]) == \"\"):\n",
        "            departure = prop[0]\n",
        "            #print(\"departure 15: \",prop[0])\n",
        "          else:\n",
        "            departure = city[0]\n",
        "          # print(\"departure 14: \",city[0])\n",
        "      elif valeur[4] == str(adp[0]):\n",
        "        if(str(city[0]) == \"\"):\n",
        "          departure = prop[0]\n",
        "          # print(\"departure 13: \",prop[0])\n",
        "        else:\n",
        "          departure = city[0]\n",
        "          # print(\"departure 12: \",city[0])\n",
        "      elif valeur[2] == str(adp[0]) and str(verb[2]) == \"être\":\n",
        "        if(str(city[0]) == \"\"):\n",
        "          departure = prop[0]\n",
        "          # print(\"departure 11: \",prop[0])\n",
        "        else:\n",
        "          departure = city[0]\n",
        "          # print(\"departure 10: \",city[0])\n",
        "      elif valeur[2] == str(adp[0]):\n",
        "        if(str(city[1]) == \"\"):\n",
        "          departure = prop[1]\n",
        "          # print(\"departure 9: \",prop[1])\n",
        "        else:\n",
        "          if len(city) >= 3 and verb[7] == \"donne\":\n",
        "            departure = city[1] \n",
        "            print(\"departure 8 : \",)\n",
        "          elif len(city) == 3:\n",
        "            departure = city[2]\n",
        "          else: \n",
        "            departure = city[1]\n",
        "          \n",
        "      elif valeur[2] == str(adp[0]):\n",
        "        if(str(city[1]) == \"\"):\n",
        "          departure = prop[1]\n",
        "          #print(\"departure 7 : \",prop[1])\n",
        "        else:\n",
        "          departure = city[1]\n",
        "          #print(\"departure 6 : \",city[1])\n",
        "      elif valeur[1] == str(adp[0]) or str(adp[1]):\n",
        "        if(str(city[1]) == \"\"):\n",
        "          departure = prop[1]\n",
        "          #print(\"departure 5 : \",prop[1])\n",
        "        else:\n",
        "          departure = city[1]\n",
        "          #print(\"departure 4 : \",city[1])\n",
        "      elif valeur[3] == str(adp[1]):\n",
        "        if(str(city[1]) == \"\"):\n",
        "          departure = prop[1]\n",
        "          #print(\"departure 3 : \",prop[1])\n",
        "        else:\n",
        "          departure = city[1]\n",
        "          #print(\"departure 3 : \",city[1])\n",
        "      else:\n",
        "        if(str(city[0]) == \"\"):\n",
        "          departure = prop[0]\n",
        "          #print(\"departure 2 : \",prop[0])\n",
        "        else:\n",
        "          departure = city[0]\n",
        "          #print(\"departure 1 : \",city[0])\n",
        "      return departure\n",
        "return_departure(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "gdkIsXdpwpyy",
        "outputId": "3a4e6788-9533-422f-cfb4-4c0f4dd9e190"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['McDonald', 'KFC']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-5762b2ccfdbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m           \u001b[0;31m#print(\"departure 1 : \",city[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mdeparture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mreturn_departure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"je veux aller chez McDonald et rejoindre KFC \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-5762b2ccfdbe>\u001b[0m in \u001b[0;36mreturn_departure\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     88\u001b[0m           \u001b[0mdeparture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0;31m#print(\"departure 6 : \",city[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       \u001b[0;32melif\u001b[0m \u001b[0mvaleur\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m           \u001b[0mdeparture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_POS(sentence):\n",
        "  if(sentence == \"\"):\n",
        "    print(\"veuillez saisir votre trajet\")\n",
        "  else:\n",
        "    departure = return_departure(sentence)\n",
        "    arrival = return_arrival(sentence)\n",
        "  return departure, arrival\n",
        "return_POS(\"De Brest à Nantes en train\")"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-01-07T14:00:02.589434Z",
          "iopub.execute_input": "2022-01-07T14:00:02.589746Z",
          "iopub.status.idle": "2022-01-07T14:00:02.700159Z",
          "shell.execute_reply.started": "2022-01-07T14:00:02.589712Z",
          "shell.execute_reply": "2022-01-07T14:00:02.698988Z"
        },
        "trusted": true,
        "id": "86yu1_5g4qpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcab872-73e8-4709-b459-4488db28b0a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Brest', 'Nantes']\n",
            "arrival :  Nantes\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Brest', 'Nantes')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Il est possible d'utiliser la fonction sans record audio\n",
        "# Dans ce cas là, il faut set le param text\n",
        "\n",
        "# record => Si True, lance un record sur le micro\n",
        "# text => Si record=False, alors ce sera le text qui sera pris en compte dans le traitement\n",
        "# view_audio_return => Si True, un bloc audio va être retourné en plus, cela permet d'écouter le record\n",
        "# record_time => Durée (en secondes) de l'enregistrement audio\n",
        "def main_function(record=True, text=None, view_audio_return=True, record_time=4, isTest=False):\n",
        "    sentence = ''\n",
        "    if record is True:\n",
        "      record_new_audio_and_save_it(view_audio_return=view_audio_return, record_time=record_time)\n",
        "      sentence = speech_to_text()\n",
        "    else:\n",
        "      if text is not None:\n",
        "        sentence = text\n",
        "      else:\n",
        "        print('/!\\ Please, set the `text` param')\n",
        "        return False\n",
        "    \n",
        "    # Check if the text is in french\n",
        "    if (check_if_text_accepted_language(sentence)):\n",
        "      departure, arrival = return_POS(sentence)\n",
        "      if departure and arrival:\n",
        "        print('Departure found :: ' + departure)\n",
        "        print('Arrival found :: ' + arrival)\n",
        "        if isTest is True:\n",
        "          return True, departure, arrival\n",
        "      else:\n",
        "        print('/!\\ I did not understand very well')\n",
        "    else:\n",
        "      print('/!\\ Please, speak french')\n",
        "      return False\n",
        "  "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T12:34:07.708287Z",
          "iopub.execute_input": "2021-12-16T12:34:07.708818Z",
          "iopub.status.idle": "2021-12-16T12:34:07.714672Z",
          "shell.execute_reply.started": "2021-12-16T12:34:07.708742Z",
          "shell.execute_reply": "2021-12-16T12:34:07.71369Z"
        },
        "trusted": true,
        "id": "1jjwqi1L4qpd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_function(\n",
        "    record=True,\n",
        "    view_audio_return=True,\n",
        "    record_time=3\n",
        "  )\n",
        "print(\"-------------\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T12:34:10.306653Z",
          "iopub.execute_input": "2021-12-16T12:34:10.307532Z",
          "iopub.status.idle": "2021-12-16T12:34:11.371558Z",
          "shell.execute_reply.started": "2021-12-16T12:34:10.307458Z",
          "shell.execute_reply": "2021-12-16T12:34:11.370491Z"
        },
        "trusted": true,
        "id": "H9sfDY584qpd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "8b2e0f3c-0e51-4620-e69d-526393a25d27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-dfd086436b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mview_audio_return\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrecord_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   )\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-131bfd3c4236>\u001b[0m in \u001b[0;36mmain_function\u001b[0;34m(record, text, view_audio_return, record_time, isTest)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mrecord_new_audio_and_save_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview_audio_return\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mview_audio_return\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'record_new_audio_and_save_it' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing part:\n",
        "\n",
        "Avant de lancer les tests:\n",
        "\n",
        "\n",
        "*   Télécharger le dataset à cette [adresse](https://docs.google.com/spreadsheets/d/15NJFAdmLEO3WwihoUif9T_U09vlIrvgoROKcAetUlz4/edit#gid=0)\n",
        "*   Importer le fichier dans Colab\n",
        "*   Renommer le en 'dataset.csv'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tPSGnieqlZI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "DATASET_NAME_FILE='dataset.csv'\n",
        "\n",
        "def import_dataset():\n",
        "  dataset = []\n",
        "  with open(DATASET_NAME_FILE, 'r') as csvfile:\n",
        "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "    for row in spamreader:\n",
        "      sentence = row[0]\n",
        "      departure = row[1]\n",
        "      arrival = row[2]\n",
        "      dataset.append([sentence, departure, arrival])\n",
        "    dataset.pop(0)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def do_test(dataset=import_dataset()):\n",
        "  TOTAL_DATA = len(dataset)\n",
        "  TESTING = 0\n",
        "  TOTAL_SUCCESS = 0\n",
        "  TOTAL_FAIL = 0\n",
        "\n",
        "  print(TOTAL_DATA)\n",
        "  for data in dataset:\n",
        "    TESTING = TESTING + 1\n",
        "    print('testing', TESTING, '...')\n",
        "\n",
        "    t = main_function(\n",
        "      record=False,\n",
        "      text=data[0],\n",
        "      view_audio_return=False,\n",
        "      isTest=True\n",
        "    )\n",
        "    \n",
        "    if t[0] is True and (t[1] == data[1]) and (t[2] == data[2]):\n",
        "      TOTAL_SUCCESS = TOTAL_SUCCESS + 1\n",
        "    else:\n",
        "      TOTAL_FAIL = TOTAL_FAIL + 1\n",
        "      print('/!\\ FAIL HERE')\n",
        "\n",
        "    print('Objectif => Sentence:', data[0], '; Departure;', data[1], '; Arrival:', data[2])\n",
        "    print(\"-------------\")\n",
        "  \n",
        "  print('Total data :: ', TOTAL_DATA)\n",
        "  print('Total success ::', TOTAL_SUCCESS)\n",
        "  print('Total failure ::', TOTAL_FAIL)\n",
        "  print('Efficiency', (TOTAL_SUCCESS/TOTAL_DATA)*100, '%')\n",
        "  print('Echec', (TOTAL_FAIL/TOTAL_DATA)*100, '%')\n",
        "\n",
        "do_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O7tUq-J1ldiv",
        "outputId": "ff59927f-e8ed-4b3e-a54c-46dbf44f8268"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n",
            "testing 1 ...\n",
            "['Paris', 'Marseille']\n",
            "Departure found :: Marseille\n",
            "Arrival found :: Paris\n",
            "Objectif => Sentence: je voudrais partir à Paris pour me rendre à Marseille ; Departure; Marseille ; Arrival: Paris\n",
            "-------------\n",
            "testing 2 ...\n",
            "['Paris', 'Marseille']\n",
            "Departure found :: Marseille\n",
            "Arrival found :: Paris\n",
            "Objectif => Sentence: comment pourai-je me rendre à Paris depuis Marseille ; Departure; Marseille ; Arrival: Paris\n",
            "-------------\n",
            "testing 3 ...\n",
            "['Marseille', 'Paris']\n",
            "Departure found :: Paris\n",
            "Arrival found :: Marseille\n",
            "Objectif => Sentence: Je veux aller à Marseille depuis Paris ; Departure; Paris ; Arrival: Marseille\n",
            "-------------\n",
            "testing 4 ...\n",
            "['Marseille', 'Paris']\n",
            "arrival :  Paris\n",
            "Departure found :: Marseille\n",
            "Arrival found :: Paris\n",
            "Objectif => Sentence: je souhaite partir de Marseille à Paris ; Departure; Marseille ; Arrival: Paris\n",
            "-------------\n",
            "testing 5 ...\n",
            "['Marseille', 'Paris']\n",
            "arrival :  Paris\n",
            "Departure found :: Marseille\n",
            "Arrival found :: Paris\n",
            "Objectif => Sentence: je veux partir depuis Marseille vers Paris ; Departure; Marseille ; Arrival: Paris\n",
            "-------------\n",
            "testing 6 ...\n",
            "['Paris', 'Marseille']\n",
            "arrival :  Marseille\n",
            "Departure found :: Paris\n",
            "Arrival found :: Marseille\n",
            "/!\\ FAIL HERE\n",
            "Objectif => Sentence: je voudrais rejoindre Paris depuis Marseille ; Departure; Marseille ; Arrival: Paris\n",
            "-------------\n",
            "testing 7 ...\n",
            "['Marseille', 'Paris']\n",
            "Departure found :: Paris\n",
            "Arrival found :: Marseille\n",
            "Objectif => Sentence: Comment je fais pour aller à Marseille en passant par Paris ; Departure; Paris ; Arrival: Marseille\n",
            "-------------\n",
            "testing 8 ...\n",
            "['Marseille', 'Paris']\n",
            "arrival :  Paris\n",
            "Departure found :: Marseille\n",
            "Arrival found :: Paris\n",
            "Objectif => Sentence: Je veux aller de Marseille vers Paris ; Departure; Marseille ; Arrival: Paris\n",
            "-------------\n",
            "testing 9 ...\n",
            "['Marseille', 'Paris']\n",
            "arrival :  Paris\n",
            "Departure found :: Marseille\n",
            "Arrival found :: Paris\n",
            "Objectif => Sentence: Le chemin pour aller de Marseille à Paris ; Departure; Marseille ; Arrival: Paris\n",
            "-------------\n",
            "testing 10 ...\n",
            "['Paris', 'Marseille']\n",
            "Departure found :: Marseille\n",
            "Arrival found :: Paris\n",
            "Objectif => Sentence: Pour me rendre à  Paris depuis Marseille quelle chemin dois-je prendre ? ; Departure; Marseille ; Arrival: Paris\n",
            "-------------\n",
            "testing 11 ...\n",
            "['Lille', 'Bordeaux']\n",
            "Departure found :: Bordeaux\n",
            "Arrival found :: Lille\n",
            "Objectif => Sentence: Je souhaite me rendre à Lille je suis actuellement à Bordeaux ; Departure; Bordeaux ; Arrival: Lille\n",
            "-------------\n",
            "testing 12 ...\n",
            "['Paris', 'Marseille']\n",
            "arrival :  Marseille\n",
            "Departure found :: Paris\n",
            "Arrival found :: Marseille\n",
            "Objectif => Sentence: Train de Paris à Marseille ; Departure; Paris ; Arrival: Marseille\n",
            "-------------\n",
            "testing 13 ...\n",
            "['Paris', 'la France', 'gare de Nice']\n",
            "Departure found :: gare de Nice\n",
            "Arrival found :: Paris\n",
            "Objectif => Sentence: Je veux me rendre à Paris je suis du Sud de la France je peux utiliser la gare de Nice ; Departure; gare de Nice ; Arrival: Paris\n",
            "-------------\n",
            "testing 14 ...\n",
            "['Lille', 'Paris', 'Lille']\n",
            "departure 8 : \n",
            "Departure found :: Paris\n",
            "Arrival found :: Lille\n",
            "Objectif => Sentence: Je pars à Lille pour les vacances donne moi le trajet Paris - Lille ; Departure; Paris ; Arrival: Lille\n",
            "-------------\n",
            "testing 15 ...\n",
            "['Brest', 'Nantes']\n",
            "arrival :  Nantes\n",
            "Departure found :: Brest\n",
            "Arrival found :: Nantes\n",
            "Objectif => Sentence: Donne moi le trajet le plus rapide pour faire Brest - Nantes en train ; Departure; Brest ; Arrival: Nantes\n",
            "-------------\n",
            "testing 16 ...\n",
            "['Brest', 'Bordeaux']\n",
            "Departure found :: Bordeaux\n",
            "Arrival found :: Brest\n",
            "Objectif => Sentence: Comment me rendre à Brest ? Je viens de Bordeaux ; Departure; Bordeaux ; Arrival: Brest\n",
            "-------------\n",
            "testing 17 ...\n",
            "['Paris', 'Marseille']\n",
            "arrival :  Marseille\n",
            "Departure found :: Paris\n",
            "Arrival found :: Marseille\n",
            "Objectif => Sentence: Paris - Marseille ; Departure; Paris ; Arrival: Marseille\n",
            "-------------\n",
            "testing 18 ...\n",
            "['Nice', 'Marseille']\n",
            "Departure found :: Nice\n",
            "Arrival found :: Marseille\n",
            "Objectif => Sentence: Bonjour je suis actuellement à Nice et je veux me rendre à Marseille ; Departure; Nice ; Arrival: Marseille\n",
            "-------------\n",
            "testing 19 ...\n",
            "['Marseille', 'Lyon']\n",
            "Departure found :: Lyon\n",
            "Arrival found :: Marseille\n",
            "Objectif => Sentence: Comment puis-je me rendre à Marseille en partant de Lyon ? ; Departure; Lyon ; Arrival: Marseille\n",
            "-------------\n",
            "testing 20 ...\n",
            "['Lyon', 'Toulouse']\n",
            "Departure found :: Toulouse\n",
            "Arrival found :: Lyon\n",
            "Objectif => Sentence: Je voudrai aller chez mes parents qui habite à Lyon. J'habite à Toulouse ; Departure; Toulouse ; Arrival: Lyon\n",
            "-------------\n",
            "testing 21 ...\n",
            "['Dijon', 'Rennes']\n",
            "Departure found :: Rennes\n",
            "Arrival found :: Dijon\n",
            "/!\\ FAIL HERE\n",
            "Objectif => Sentence: Je suis à Dijon. Comment aller à Rennes ? ; Departure; Dijon ; Arrival: Rennes\n",
            "-------------\n",
            "testing 22 ...\n",
            "['Lyon', 'Limoges']\n",
            "arrival :  Limoges\n",
            "Departure found :: Lyon\n",
            "Arrival found :: Limoges\n",
            "Objectif => Sentence: Le trajet le plus rapide entre Lyon et Limoges ; Departure; Lyon ; Arrival: Limoges\n",
            "-------------\n",
            "testing 23 ...\n",
            "['Aix-en-Provence', 'Monaco']\n",
            "arrival :  Monaco\n",
            "Departure found :: Aix-en-Provence\n",
            "Arrival found :: Monaco\n",
            "Objectif => Sentence: Trajet depuis Aix-en-Provence à Monaco ; Departure; Aix-en-Provence ; Arrival: Monaco\n",
            "-------------\n",
            "testing 24 ...\n",
            "['Angers', 'Paris']\n",
            "Departure found :: Paris\n",
            "Arrival found :: Angers\n",
            "Objectif => Sentence: Train pour aller à Angers en provenance de Paris ; Departure; Paris ; Arrival: Angers\n",
            "-------------\n",
            "testing 25 ...\n",
            "['Brest', 'Nantes']\n",
            "arrival :  Nantes\n",
            "Departure found :: Brest\n",
            "Arrival found :: Nantes\n",
            "Objectif => Sentence: De Brest à Nantes en train ; Departure; Brest ; Arrival: Nantes\n",
            "-------------\n",
            "testing 26 ...\n",
            "['Grenoble', 'Paris']\n",
            "Departure found :: Paris\n",
            "Arrival found :: Grenoble\n",
            "Objectif => Sentence: Je voudrai aller faire du ski à Grenoble. Je suis de Paris ; Departure; Paris ; Arrival: Grenoble\n",
            "-------------\n",
            "testing 27 ...\n",
            "['Marseille', 'Perpignan']\n",
            "arrival :  Perpignan\n",
            "Departure found :: Marseille\n",
            "Arrival found :: Perpignan\n",
            "Objectif => Sentence: Trajet entre Marseille et Perpignan ; Departure; Marseille ; Arrival: Perpignan\n",
            "-------------\n",
            "testing 28 ...\n",
            "['Nice', 'Cannes']\n",
            "arrival :  Cannes\n",
            "Departure found :: Nice\n",
            "Arrival found :: Cannes\n",
            "Objectif => Sentence: Combien de temps faut-il pour aller de Nice à Cannes? ; Departure; Nice ; Arrival: Cannes\n",
            "-------------\n",
            "testing 29 ...\n",
            "['Grenoble', 'Genève']\n",
            "arrival :  Genève\n",
            "Departure found :: Grenoble\n",
            "Arrival found :: Genève\n",
            "Objectif => Sentence: Comment aller de Grenoble à Genève? ; Departure; Grenoble ; Arrival: Genève\n",
            "-------------\n",
            "testing 30 ...\n",
            "/!\\ Please, speak french\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-109def94c3e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Echec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTOTAL_FAIL\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTOTAL_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mdo_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-109def94c3e6>\u001b[0m in \u001b[0;36mdo_test\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0mTOTAL_SUCCESS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOTAL_SUCCESS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}